#file: noinspection SpringBootApplicationYaml
server:
  port: 8087
  tomcat:
    threads:
      max: 200        # 设定处理客户请求的线程的最大数目，决定了服务器可以同时响应客户请求的数,默认200
      min-spare: 50   # 初始化线程数,最小空闲线程数,默认是10
    accept-count: 10  # 等待队列长度
  servlet:
    context-path: /api/${app.config.api-version}

# 应用配置 app.config.api-version
app:
  config:
    # 版本，方便通过接口版本升级
    api-version: v1
    # 跨域，开发阶段可以设置为 * 不限制
    cross-origin:  '*'

#  -Djasypt.encryptor.password=lijiaqiang1024@wt1314520
#java -Djasypt.encryptor.password=lijiaqiang1024@wt1314520 -jar course-push-app.jar
jasypt:
  encryptor:
    algorithm: PBEWithMD5AndDES
    password: ${JASYPT_ENCRYPTOR_PASSWORD}
    iv-generator-classname: org.jasypt.iv.NoIvGenerator
    property:
      prefix: ENC(
      suffix: )

# 线程池配置
thread:
  pool:
    executor:
      config:
        core-pool-size: 20
        max-pool-size: 50
        keep-alive-time: 5000
        block-queue-size: 5000
        policy: CallerRunsPolicy

spring:
  main:
    web-application-type: none
  # ollama ai
  ai:
    mcp:
      client:
        stdio:
          servers-configuration: classpath:/config/config.json
    openai:
#      base-url: https://apis.itedus.cn/  # chat-gpt
      base-url: https://dashscope.aliyuncs.com/compatible-mode  # qwen3
#      api-key: sk-eQ9OYl82ujfFPe682a26F4D0B8534c1281D32d1e724f6aBa  # chat-gpt
      api-key: your_key  # qwen3
      chat:
        options:
#          model: gpt-4.1-mini
          model: qwen-flash
      vector-table-name: vector_store_openai
      embedding:
        options:
          num-batch: 1536
          model: text-embedding-ada-002
    ollama:
      base-url: http://127.0.0.1:11434
      chat:
        options:
          model: qwen3:14B
      embedding-model: nomic-embed-text
      vector-table-name: vector_store_ollama_deepseek
      # 向量模型
      embedding:
        options:
          # 配置模型处理的批量大小，这里设置为512。表示模型一次可以处理 512 个文本片段的嵌入请求
          num-batch: 768
    zhipuai:
      vector-table-name: vector_store_zhipuai
      image:
        base-url: https://open.bigmodel.cn/api/paas
        api-key: c3e3912426c49a7b990280b1d2d235a3.tcgJOlShzn6ba6uk
        options:
          model: GLM-4V-Flash
      chat:
        api-key: c3e3912426c49a7b990280b1d2d235a3.tcgJOlShzn6ba6uk
        base-url: https://open.bigmodel.cn/api/paas
        options:
          model: GLM-4.5-Flash # GLM-4-Flash-250414
          temperature: 0.7  # 设置温度参数
      embedding:
        options:
          dimensions: 1024
          model: embedding-3

  # 向量数据库
  datasource:
    driver-class-name: org.postgresql.Driver
    username: ENC(kT6cWGip6fSnLJz5WVhGyaFeuFLsCQ6P)
    password: ENC(ny4D4WfjIPT9HhmlnXF5/7mY6JLchT+L)
    url: jdbc:postgresql://127.0.0.1:15432/ai-rag-knowledge
    type: com.zaxxer.hikari.HikariDataSource
    # hikari连接池配置
    hikari:
      #连接池名
      pool-name: HikariCP
      #最小空闲连接数
      minimum-idle: 5
      # 空闲连接存活最大时间，默认10分钟
      idle-timeout: 600000
      # 连接池最大连接数，默认是10
      maximum-pool-size: 10
      # 此属性控制从池返回的连接的默认自动提交行为,默认值：true
      auto-commit: true
      # 此属性控制池中连接的最长生命周期，值0表示无限生命周期，默认30分钟
      max-lifetime: 1800000
      # 数据库连接超时时间,默认30秒
      connection-timeout: 30000
      # 连接测试query
      connection-test-query: SELECT 1


jq1024:
  cc:
    # redisson 配置
    redisson:
      host: 127.0.0.1
      port: ENC(IoLWVdM0/gTgs+XZ+Gq8nA==)
      password: ENC(Xo8agmA26A3MM5iD1uGiwM1BOzNIN9zI)
      database: 0
      pool-size: 10
      min-idle-size: 5
      idle-timeout: 30000
      connect-timeout: 5000
      retry-attempts: 3
      retry-interval: 1000
      ping-interval: 60000
      keep-alive: true

logging:
  level:
    root: info
  config: classpath:logback-spring.xml